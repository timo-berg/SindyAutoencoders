{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 08:13:52.796681: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-06 08:13:54.506394: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_pendulum import get_pendulum_data\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pendulum data with noise\n",
      "Generating pendulum data\n"
     ]
    }
   ],
   "source": [
    "training_data = get_pendulum_data(100, True)\n",
    "validation_data = get_pendulum_data(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params['input_dim'] = training_data['x'].shape[-1]\n",
    "params['latent_dim'] = 1\n",
    "params['model_order'] = 2\n",
    "params['poly_order'] = 3\n",
    "params['include_sine'] = True\n",
    "params['library_dim'] = library_size(2*params['latent_dim'], params['poly_order'], params['include_sine'], True)\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = True\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 500\n",
    "params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_x'] = 5e-4\n",
    "params['loss_weight_sindy_z'] = 5e-5\n",
    "params['loss_weight_sindy_regularization'] = 1e-5\n",
    "\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [128,64,32]\n",
    "\n",
    "# training parameters\n",
    "params['epoch_size'] = training_data['x'].shape[0]\n",
    "params['batch_size'] = 1000\n",
    "params['learning_rate'] = 1e-4\n",
    "\n",
    "params['data_path'] = os.getcwd() + '/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 100\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 5001\n",
    "params['refinement_epochs'] = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n",
      "TRAINING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 08:14:15.948675: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-06 08:14:17.984520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-06 08:14:17.984610: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-06 08:14:17.996628: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-06 08:14:17.996759: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-06 08:14:17.996815: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-06 08:14:18.762061: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-06 08:14:18.762206: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-06 08:14:18.762258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-06 08:14:18.762346: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-06 08:14:18.762493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6687 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:0a:00.0, compute capability: 6.1\n",
      "2024-06-06 08:14:18.846958: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "   training loss 0.015253981575369835, (0.007933256, 2.2651649, 14.395019, 0.995796)\n",
      "   validation loss 0.01606769487261772, (0.008060615, 2.28555, 15.765689, 0.995796)\n",
      "decoder loss ratio: 0.960995, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 100\n",
      "   training loss 0.01449159998446703, (0.0072873435, 2.5910507e-05, 14.395016, 0.67477417)\n",
      "   validation loss 0.015283242799341679, (0.007393649, 3.58038e-05, 15.765689, 0.67477417)\n",
      "decoder loss ratio: 0.881479, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 200\n",
      "   training loss 0.014473062008619308, (0.007272811, 0.0015033814, 14.395016, 0.26670074)\n",
      "   validation loss 0.015279869548976421, (0.007394265, 0.0018520233, 15.765688, 0.26670074)\n",
      "decoder loss ratio: 0.881552, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 300\n",
      "   training loss 0.014462979510426521, (0.007263424, 0.005699739, 14.395016, 0.17617254)\n",
      "   validation loss 0.01527830958366394, (0.0073933285, 0.00749548, 15.765688, 0.17617254)\n",
      "decoder loss ratio: 0.881441, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 400\n",
      "   training loss 0.01444457471370697, (0.0072412295, 0.09267302, 14.395016, 0.12035394)\n",
      "   validation loss 0.015266811475157738, (0.007377808, 0.09915649, 15.765685, 0.12035394)\n",
      "decoder loss ratio: 0.879590, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 500\n",
      "   training loss 0.013300602324306965, (0.0060639684, 0.80081767, 14.390969, 0.11081719)\n",
      "   validation loss 0.014373214915394783, (0.0064411196, 1.0020622, 15.761768, 0.11081719)\n",
      "decoder loss ratio: 0.767917, decoder SINDy loss  ratio: 0.999751\n",
      "THRESHOLDING: 6 active coefficients\n",
      "Epoch 600\n",
      "   training loss 0.01189277321100235, (0.0050548413, 0.9417726, 13.579596, 0.104472876)\n",
      "   validation loss 0.013081654906272888, (0.0055216174, 0.9775926, 15.020226, 0.104472876)\n",
      "decoder loss ratio: 0.658293, decoder SINDy loss  ratio: 0.952716\n",
      "Epoch 700\n",
      "   training loss 0.007818467915058136, (0.0041849967, 2.1078088, 7.054015, 0.107251205)\n",
      "   validation loss 0.00904423650354147, (0.004580434, 2.2016141, 8.705297, 0.107251205)\n",
      "decoder loss ratio: 0.546084, decoder SINDy loss  ratio: 0.552167\n",
      "Epoch 800\n",
      "   training loss 0.005188995972275734, (0.00302593, 1.8408997, 4.1395316, 0.12556443)\n",
      "   validation loss 0.006180129945278168, (0.0032504604, 2.0426426, 5.6525645, 0.12556443)\n",
      "decoder loss ratio: 0.387523, decoder SINDy loss  ratio: 0.358536\n",
      "Epoch 900\n",
      "   training loss 0.003311468753963709, (0.0021144014, 0.9436477, 2.2975264, 0.11216915)\n",
      "   validation loss 0.004231502767652273, (0.0022997116, 1.4664881, 3.71469, 0.11216915)\n",
      "decoder loss ratio: 0.274174, decoder SINDy loss  ratio: 0.235619\n",
      "Epoch 1000\n",
      "   training loss 0.0019605313427746296, (0.001383072, 0.5238688, 1.1011099, 0.0711117)\n",
      "   validation loss 0.0030012549832463264, (0.0017130934, 1.0886133, 2.4660394, 0.0711117)\n",
      "decoder loss ratio: 0.204237, decoder SINDy loss  ratio: 0.156418\n",
      "THRESHOLDING: 3 active coefficients\n",
      "Epoch 1100\n",
      "   training loss 0.0013054447481408715, (0.00096867455, 0.29105854, 0.64344656, 0.049395204)\n",
      "   validation loss 0.0022701644338667393, (0.0013387, 0.7480706, 1.7871338, 0.049395204)\n",
      "decoder loss ratio: 0.159601, decoder SINDy loss  ratio: 0.113356\n",
      "Epoch 1200\n",
      "   training loss 0.0007890071719884872, (0.0006049686, 0.2343137, 0.3438499, 0.03979884)\n",
      "   validation loss 0.0017062450060620904, (0.0010494791, 0.63469476, 1.2492664, 0.03979884)\n",
      "decoder loss ratio: 0.125120, decoder SINDy loss  ratio: 0.079240\n",
      "Epoch 1300\n",
      "   training loss 0.000518456450663507, (0.0003894066, 0.19790125, 0.23758146, 0.036402065)\n",
      "   validation loss 0.0013673068024218082, (0.0008587, 0.53698367, 0.9627872, 0.036402065)\n",
      "decoder loss ratio: 0.102375, decoder SINDy loss  ratio: 0.061069\n",
      "Epoch 1400\n",
      "   training loss 0.00035498631768859923, (0.0002513763, 0.1808373, 0.18838274, 0.037678935)\n",
      "   validation loss 0.0010820823954418302, (0.0006914117, 0.46857616, 0.73372996, 0.037678935)\n",
      "decoder loss ratio: 0.082431, decoder SINDy loss  ratio: 0.046540\n",
      "Epoch 1500\n",
      "   training loss 0.00024654128355905414, (0.00017640897, 0.16779564, 0.12274972, 0.036766745)\n",
      "   validation loss 0.0008618761785328388, (0.00056924386, 0.35609746, 0.54891956, 0.036766745)\n",
      "decoder loss ratio: 0.067866, decoder SINDy loss  ratio: 0.034817\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 1600\n",
      "   training loss 0.0001988212316064164, (0.00013565506, 0.16212383, 0.10942729, 0.03463417)\n",
      "   validation loss 0.0007231092313304543, (0.00048670586, 0.2919915, 0.44291484, 0.03463417)\n",
      "decoder loss ratio: 0.058026, decoder SINDy loss  ratio: 0.028094\n",
      "Epoch 1700\n",
      "   training loss 0.00016423776105511934, (0.0001069013, 0.1587042, 0.098113276, 0.034460537)\n",
      "   validation loss 0.0005986288306303322, (0.00041283152, 0.27187967, 0.3437175, 0.034460537)\n",
      "decoder loss ratio: 0.049218, decoder SINDy loss  ratio: 0.021802\n",
      "Epoch 1800\n",
      "   training loss 0.00013460579793900251, (8.5370244e-05, 0.15550318, 0.08223438, 0.034319196)\n",
      "   validation loss 0.0004988327855244279, (0.0003506448, 0.24689677, 0.27099997, 0.034319196)\n",
      "decoder loss ratio: 0.041804, decoder SINDy loss  ratio: 0.017189\n",
      "Epoch 1900\n",
      "   training loss 0.00013712418149225414, (7.535506e-05, 0.15274699, 0.10758638, 0.03385752)\n",
      "   validation loss 0.00045546022010967135, (0.00031010588, 0.21770743, 0.26826075, 0.03385752)\n",
      "decoder loss ratio: 0.036971, decoder SINDy loss  ratio: 0.017015\n",
      "Epoch 2000\n",
      "   training loss 0.00012708973372355103, (6.692478e-05, 0.15159184, 0.104499266, 0.033573125)\n",
      "   validation loss 0.00041387672536075115, (0.00028034643, 0.19762231, 0.24662684, 0.033573125)\n",
      "decoder loss ratio: 0.033423, decoder SINDy loss  ratio: 0.015643\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 2100\n",
      "   training loss 0.00011960284609813243, (6.097448e-05, 0.1513146, 0.10145914, 0.033306994)\n",
      "   validation loss 0.0003827693872153759, (0.00025810604, 0.18493755, 0.23016681, 0.033306994)\n",
      "decoder loss ratio: 0.030772, decoder SINDy loss  ratio: 0.014599\n",
      "Epoch 2200\n",
      "   training loss 0.00011346251267241314, (5.6516226e-05, 0.15124936, 0.09810623, 0.033070207)\n",
      "   validation loss 0.0003580526099540293, (0.00024058191, 0.17633286, 0.21664669, 0.033070207)\n",
      "decoder loss ratio: 0.028682, decoder SINDy loss  ratio: 0.013742\n",
      "Epoch 2300\n",
      "   training loss 0.0001081028749467805, (5.3027623e-05, 0.15103684, 0.094389096, 0.0328862)\n",
      "   validation loss 0.00033767582499422133, (0.00022631879, 0.17009455, 0.20504685, 0.0328862)\n",
      "decoder loss ratio: 0.026982, decoder SINDy loss  ratio: 0.013006\n",
      "Epoch 2400\n",
      "   training loss 0.00010330770601285622, (5.020485e-05, 0.1505689, 0.090493515, 0.03276485)\n",
      "   validation loss 0.0003205141983926296, (0.00021446146, 0.16542941, 0.19490725, 0.03276485)\n",
      "decoder loss ratio: 0.025568, decoder SINDy loss  ratio: 0.012363\n",
      "Epoch 2500\n",
      "   training loss 9.90025291685015e-05, (4.7871003e-05, 0.14988577, 0.08662018, 0.032714512)\n",
      "   validation loss 0.0003059376322198659, (0.00020450955, 0.16182303, 0.18601957, 0.032714512)\n",
      "decoder loss ratio: 0.024382, decoder SINDy loss  ratio: 0.011799\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 2600\n",
      "   training loss 9.517157741356641e-05, (4.5938665e-05, 0.14906985, 0.08290439, 0.032722652)\n",
      "   validation loss 0.0002935290976893157, (0.00019613653, 0.158901, 0.17824058, 0.032722652)\n",
      "decoder loss ratio: 0.023384, decoder SINDy loss  ratio: 0.011306\n",
      "Epoch 2700\n",
      "   training loss 9.170062548946589e-05, (4.430087e-05, 0.14818686, 0.079325445, 0.03276856)\n",
      "   validation loss 0.00028285535518079996, (0.00018904785, 0.15642256, 0.1713174, 0.03276856)\n",
      "decoder loss ratio: 0.022538, decoder SINDy loss  ratio: 0.010866\n",
      "Epoch 2800\n",
      "   training loss 8.508122118655592e-05, (4.2048614e-05, 0.14744526, 0.07066361, 0.032853965)\n",
      "   validation loss 0.00027031052741222084, (0.00018252543, 0.15417224, 0.15949582, 0.032853965)\n",
      "decoder loss ratio: 0.021761, decoder SINDy loss  ratio: 0.010117\n",
      "Epoch 2900\n",
      "   training loss 8.516037632944062e-05, (4.1676434e-05, 0.14555514, 0.071757175, 0.03275901)\n",
      "   validation loss 0.0002665218198671937, (0.00017858636, 0.15170224, 0.16004553, 0.03275901)\n",
      "decoder loss ratio: 0.021291, decoder SINDy loss  ratio: 0.010152\n",
      "Epoch 3000\n",
      "   training loss 8.429117588093504e-05, (4.0951716e-05, 0.14491048, 0.071532845, 0.03275151)\n",
      "   validation loss 0.00026120213442482054, (0.00017448432, 0.15018372, 0.15776229, 0.03275151)\n",
      "decoder loss ratio: 0.020802, decoder SINDy loss  ratio: 0.010007\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 3100\n",
      "   training loss 8.35239261505194e-05, (4.031481e-05, 0.14443962, 0.071318366, 0.0327948)\n",
      "   validation loss 0.00025655588251538575, (0.00017090456, 0.14893767, 0.15575299, 0.0327948)\n",
      "decoder loss ratio: 0.020375, decoder SINDy loss  ratio: 0.009879\n",
      "Epoch 3200\n",
      "   training loss 8.284192153951153e-05, (3.9758856e-05, 0.14404227, 0.07110484, 0.032852933)\n",
      "   validation loss 0.000252454134169966, (0.00016776653, 0.14784501, 0.15393361, 0.032852933)\n",
      "decoder loss ratio: 0.020001, decoder SINDy loss  ratio: 0.009764\n",
      "Epoch 3300\n",
      "   training loss 8.222270116675645e-05, (3.9262464e-05, 0.14369163, 0.07089307, 0.03291228)\n",
      "   validation loss 0.00024879357079043984, (0.00016498826, 0.14686047, 0.1522663, 0.03291228)\n",
      "decoder loss ratio: 0.019670, decoder SINDy loss  ratio: 0.009658\n",
      "Epoch 3400\n",
      "   training loss 8.165577310137451e-05, (3.8814353e-05, 0.14337613, 0.07068575, 0.032973774)\n",
      "   validation loss 0.00024549971567466855, (0.00016250911, 0.14596057, 0.15072568, 0.032973774)\n",
      "decoder loss ratio: 0.019375, decoder SINDy loss  ratio: 0.009560\n",
      "Epoch 3500\n",
      "   training loss 8.113599324133247e-05, (3.8408518e-05, 0.14309329, 0.07048474, 0.033043563)\n",
      "   validation loss 0.00024251308059319854, (0.00016028047, 0.14513469, 0.14929089, 0.033043563)\n",
      "decoder loss ratio: 0.019109, decoder SINDy loss  ratio: 0.009469\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 3600\n",
      "   training loss 8.065204747254029e-05, (3.8032966e-05, 0.14284478, 0.07029152, 0.033107627)\n",
      "   validation loss 0.0002397805656073615, (0.00015825647, 0.14438029, 0.147948, 0.033107627)\n",
      "decoder loss ratio: 0.018868, decoder SINDy loss  ratio: 0.009384\n",
      "Epoch 3700\n",
      "   training loss 8.019754022825509e-05, (3.7681373e-05, 0.14263833, 0.07010498, 0.033175837)\n",
      "   validation loss 0.0002372606541030109, (0.00015640342, 0.14369993, 0.14668097, 0.033175837)\n",
      "decoder loss ratio: 0.018647, decoder SINDy loss  ratio: 0.009304\n",
      "Epoch 3800\n",
      "   training loss 7.976686174515635e-05, (3.7346377e-05, 0.14248395, 0.06992761, 0.033248276)\n",
      "   validation loss 0.0002349185524508357, (0.00015468862, 0.143099, 0.145485, 0.033248276)\n",
      "decoder loss ratio: 0.018442, decoder SINDy loss  ratio: 0.009228\n",
      "Epoch 3900\n",
      "   training loss 7.934951281640679e-05, (3.7021495e-05, 0.14238995, 0.06975055, 0.033324175)\n",
      "   validation loss 0.00023272098042070866, (0.0001530862, 0.14257656, 0.14434543, 0.033324175)\n",
      "decoder loss ratio: 0.018251, decoder SINDy loss  ratio: 0.009156\n",
      "Epoch 4000\n",
      "   training loss 7.893796282587573e-05, (3.669614e-05, 0.14236233, 0.06957946, 0.033397704)\n",
      "   validation loss 0.00023064376728143543, (0.00015157054, 0.14212687, 0.14326583, 0.033397704)\n",
      "decoder loss ratio: 0.018070, decoder SINDy loss  ratio: 0.009087\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 4100\n",
      "   training loss 7.854637078708038e-05, (3.638083e-05, 0.14239934, 0.069421574, 0.0334791)\n",
      "   validation loss 0.00022870943939778954, (0.000150157, 0.14177063, 0.14225823, 0.0334791)\n",
      "decoder loss ratio: 0.017902, decoder SINDy loss  ratio: 0.009023\n",
      "Epoch 4200\n",
      "   training loss 7.819637539796531e-05, (3.6089008e-05, 0.14248197, 0.06929539, 0.033557005)\n",
      "   validation loss 0.00022693131177220494, (0.00014885538, 0.14148942, 0.14133178, 0.033557005)\n",
      "decoder loss ratio: 0.017747, decoder SINDy loss  ratio: 0.008965\n",
      "Epoch 4300\n",
      "   training loss 7.787024514982477e-05, (3.581192e-05, 0.14258936, 0.06918503, 0.033634152)\n",
      "   validation loss 0.00022526665998157114, (0.00014764194, 0.14122923, 0.14045385, 0.033634152)\n",
      "decoder loss ratio: 0.017602, decoder SINDy loss  ratio: 0.008909\n",
      "Epoch 4400\n",
      "   training loss 7.756994455121458e-05, (3.5552523e-05, 0.14272402, 0.06908814, 0.03371503)\n",
      "   validation loss 0.0002237019216408953, (0.00014651132, 0.14097102, 0.1396098, 0.03371503)\n",
      "decoder loss ratio: 0.017467, decoder SINDy loss  ratio: 0.008855\n",
      "Epoch 4500\n",
      "   training loss 7.72837083786726e-05, (3.530105e-05, 0.142891, 0.06900037, 0.033792805)\n",
      "   validation loss 0.0002222161419922486, (0.00014544703, 0.1407122, 0.13879116, 0.033792805)\n",
      "decoder loss ratio: 0.017340, decoder SINDy loss  ratio: 0.008803\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 4600\n",
      "   training loss 7.701235153945163e-05, (3.5055793e-05, 0.14309008, 0.06892666, 0.03387189)\n",
      "   validation loss 0.00022079850896261632, (0.00014444087, 0.14044617, 0.13799322, 0.03387189)\n",
      "decoder loss ratio: 0.017220, decoder SINDy loss  ratio: 0.008753\n",
      "Epoch 4700\n",
      "   training loss 7.675354572711512e-05, (3.4814304e-05, 0.14331345, 0.06886803, 0.033954937)\n",
      "   validation loss 0.00021943783212918788, (0.00014348504, 0.14015955, 0.1372105, 0.033954937)\n",
      "decoder loss ratio: 0.017106, decoder SINDy loss  ratio: 0.008703\n",
      "Epoch 4800\n",
      "   training loss 7.650905172340572e-05, (3.457637e-05, 0.1435477, 0.068829834, 0.03403847)\n",
      "   validation loss 0.00021813000785186887, (0.00014257539, 0.13983767, 0.13644469, 0.03403847)\n",
      "decoder loss ratio: 0.016998, decoder SINDy loss  ratio: 0.008655\n",
      "Epoch 4900\n",
      "   training loss 7.627755257999524e-05, (3.434097e-05, 0.1437757, 0.068813086, 0.03412499)\n",
      "   validation loss 0.00021687163098249584, (0.00014170895, 0.13947146, 0.13569568, 0.03412499)\n",
      "decoder loss ratio: 0.016895, decoder SINDy loss  ratio: 0.008607\n",
      "Epoch 5000\n",
      "   training loss 7.605188875459135e-05, (3.4103545e-05, 0.14398165, 0.06881413, 0.03421932)\n",
      "   validation loss 0.00021565711358562112, (0.00014088064, 0.13906172, 0.1349624, 0.03421932)\n",
      "decoder loss ratio: 0.016796, decoder SINDy loss  ratio: 0.008561\n",
      "THRESHOLDING: 2 active coefficients\n",
      "REFINEMENT\n",
      "Epoch 0\n",
      "   training loss 7.71392515162006e-05, (3.1585565e-05, 0.14436325, 0.07667105, 0.034292966)\n",
      "   validation loss 0.00021410296903923154, (0.00013659742, 0.13876049, 0.14113507, 0.034292966)\n",
      "decoder loss ratio: 0.016285, decoder SINDy loss  ratio: 0.008952\n",
      "Epoch 100\n",
      "   training loss 7.539932994404808e-05, (3.386837e-05, 0.14401892, 0.06866002, 0.03475562)\n",
      "   validation loss 0.00021412370551843196, (0.00014006738, 0.13878132, 0.13423452, 0.03475562)\n",
      "decoder loss ratio: 0.016699, decoder SINDy loss  ratio: 0.008514\n",
      "Epoch 200\n",
      "   training loss 7.519376958953217e-05, (3.3639e-05, 0.14412393, 0.06869715, 0.034883175)\n",
      "   validation loss 0.0002130081702489406, (0.00013932436, 0.13829118, 0.13353848, 0.034883175)\n",
      "decoder loss ratio: 0.016610, decoder SINDy loss  ratio: 0.008470\n",
      "Epoch 300\n",
      "   training loss 7.499126513721421e-05, (3.340473e-05, 0.14414942, 0.06875813, 0.034985006)\n",
      "   validation loss 0.0002119429555023089, (0.00013862096, 0.13774331, 0.13286966, 0.034985006)\n",
      "decoder loss ratio: 0.016527, decoder SINDy loss  ratio: 0.008428\n",
      "Epoch 400\n",
      "   training loss 7.478953921236098e-05, (3.3164655e-05, 0.14409363, 0.0688404, 0.03508258)\n",
      "   validation loss 0.00021092090173624456, (0.00013794893, 0.13715427, 0.13222852, 0.03508258)\n",
      "decoder loss ratio: 0.016446, decoder SINDy loss  ratio: 0.008387\n",
      "Epoch 500\n",
      "   training loss 7.4596464401111e-05, (3.2931202e-05, 0.14396217, 0.068934314, 0.03517912)\n",
      "   validation loss 0.0002099390549119562, (0.0001373096, 0.13653317, 0.13160561, 0.03517912)\n",
      "decoder loss ratio: 0.016370, decoder SINDy loss  ratio: 0.008348\n",
      "Epoch 600\n",
      "   training loss 7.440487388521433e-05, (3.2694057e-05, 0.14376259, 0.069045365, 0.03527625)\n",
      "   validation loss 0.00020899128867313266, (0.00013669154, 0.13589168, 0.13101035, 0.03527625)\n",
      "decoder loss ratio: 0.016297, decoder SINDy loss  ratio: 0.008310\n",
      "Epoch 700\n",
      "   training loss 7.421104237437248e-05, (3.2455853e-05, 0.14349747, 0.06916063, 0.035374254)\n",
      "   validation loss 0.00020807242253795266, (0.00013609516, 0.13523732, 0.13043077, 0.035374254)\n",
      "decoder loss ratio: 0.016225, decoder SINDy loss  ratio: 0.008273\n",
      "Epoch 800\n",
      "   training loss 7.402939809253439e-05, (3.222756e-05, 0.14315994, 0.06928768, 0.03547321)\n",
      "   validation loss 0.00020719639724120498, (0.00013552653, 0.13457425, 0.12988229, 0.03547321)\n",
      "decoder loss ratio: 0.016158, decoder SINDy loss  ratio: 0.008238\n",
      "Epoch 900\n",
      "   training loss 7.384915079455823e-05, (3.200451e-05, 0.14275597, 0.06941367, 0.03557305)\n",
      "   validation loss 0.00020635168766602874, (0.00013497737, 0.13391395, 0.12935725, 0.03557305)\n",
      "decoder loss ratio: 0.016092, decoder SINDy loss  ratio: 0.008205\n",
      "Epoch 1000\n",
      "   training loss 7.36845177016221e-05, (3.179873e-05, 0.1423051, 0.06954107, 0.035674863)\n",
      "   validation loss 0.00020554836373776197, (0.00013445482, 0.13327226, 0.12885985, 0.035674863)\n",
      "decoder loss ratio: 0.016030, decoder SINDy loss  ratio: 0.008173\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_712289/3717215364.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mresults_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'experiment_results_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d%H%M\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "num_experiments = 10\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_experiments):\n",
    "    print('EXPERIMENT %d' % i)\n",
    "\n",
    "    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "\n",
    "    params['save_name'] = 'pendulum_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    results_dict = train_network(training_data, validation_data, params)\n",
    "    df = df.append({**results_dict, **params}, ignore_index=True)\n",
    "\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
