{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_pendulum import get_pendulum_data\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pendulum data with noise\n",
      "Generating pendulum data\n"
     ]
    }
   ],
   "source": [
    "training_data = get_pendulum_data(100, True)\n",
    "validation_data = get_pendulum_data(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params['input_dim'] = training_data['x'].shape[-1]\n",
    "params['latent_dim'] = 1\n",
    "params['model_order'] = 2\n",
    "params['poly_order'] = 3\n",
    "params['include_sine'] = True\n",
    "params['library_dim'] = library_size(2*params['latent_dim'], params['poly_order'], params['include_sine'], True)\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = True\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 500\n",
    "params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_x'] = 5e-4\n",
    "params['loss_weight_sindy_z'] = 5e-5\n",
    "params['loss_weight_sindy_regularization'] = 1e-5\n",
    "\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [128,64,32]\n",
    "\n",
    "# training parameters\n",
    "params['epoch_size'] = training_data['x'].shape[0]\n",
    "params['batch_size'] = 1000\n",
    "params['learning_rate'] = 1e-4\n",
    "\n",
    "params['data_path'] = os.getcwd() + '/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 100\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 5001\n",
    "params['refinement_epochs'] = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n",
      "TRAINING\n",
      "Epoch 0\n",
      "   training loss 0.010535256005823612, (0.007856007, 0.32767388, 5.3058076, 0.9961781)\n",
      "   validation loss 0.017946472391486168, (0.008318123, 0.32703128, 19.204071, 0.9961781)\n",
      "decoder loss ratio: 0.991696, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 100\n",
      "   training loss 0.009700222872197628, (0.0070414655, 6.4593223e-06, 5.3058066, 0.58533174)\n",
      "   validation loss 0.017183832824230194, (0.0075759427, 2.9059416e-05, 19.204071, 0.58533174)\n",
      "decoder loss ratio: 0.903212, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 200\n",
      "   training loss 0.009680281393229961, (0.007025956, 0.00021856307, 5.3058066, 0.14108706)\n",
      "   validation loss 0.01717873476445675, (0.007575241, 0.0009545783, 19.204073, 0.14108706)\n",
      "decoder loss ratio: 0.903128, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 300\n",
      "   training loss 0.009680494666099548, (0.007027168, 0.0007444198, 5.3058066, 0.038596053)\n",
      "   validation loss 0.017174245789647102, (0.0075716334, 0.0038061035, 19.204073, 0.038596053)\n",
      "decoder loss ratio: 0.902698, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 400\n",
      "   training loss 0.009675632230937481, (0.0070220316, 0.01149408, 5.3058066, 0.012185457)\n",
      "   validation loss 0.017171941697597504, (0.0075673074, 0.04952514, 19.204071, 0.012185457)\n",
      "decoder loss ratio: 0.902183, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 500\n",
      "   training loss 0.008821443654596806, (0.0061293077, 0.7900896, 5.303106, 0.107892536)\n",
      "   validation loss 0.01638246700167656, (0.0066943346, 1.7861595, 19.195492, 0.107892536)\n",
      "decoder loss ratio: 0.798106, decoder SINDy loss  ratio: 0.999553\n",
      "THRESHOLDING: 5 active coefficients\n",
      "Epoch 600\n",
      "   training loss 0.0069916886277496815, (0.0044474048, 1.4636323, 4.939959, 0.112250805)\n",
      "   validation loss 0.014798303134739399, (0.0056968676, 1.8337659, 18.017248, 0.112250805)\n",
      "decoder loss ratio: 0.679187, decoder SINDy loss  ratio: 0.938199\n",
      "Epoch 700\n",
      "   training loss 0.004574347287416458, (0.0031407012, 1.3108547, 2.7343729, 0.091699414)\n",
      "   validation loss 0.010886686854064465, (0.0048476625, 3.26777, 11.749435, 0.091699414)\n",
      "decoder loss ratio: 0.577944, decoder SINDy loss  ratio: 0.611820\n",
      "Epoch 800\n",
      "   training loss 0.0029393613804131746, (0.0021766343, 0.64824224, 1.4584113, 0.11091307)\n",
      "   validation loss 0.008014586754143238, (0.0039377194, 2.7323072, 7.878285, 0.11091307)\n",
      "decoder loss ratio: 0.469459, decoder SINDy loss  ratio: 0.410240\n",
      "Epoch 900\n",
      "   training loss 0.001959417248144746, (0.0015897561, 0.3303109, 0.70415956, 0.10658494)\n",
      "   validation loss 0.005952642764896154, (0.0031818366, 1.8949113, 5.34999, 0.10658494)\n",
      "decoder loss ratio: 0.379342, decoder SINDy loss  ratio: 0.278586\n",
      "Epoch 1000\n",
      "   training loss 0.0012475000694394112, (0.001067786, 0.27121362, 0.33077687, 0.07650198)\n",
      "   validation loss 0.004543287213891745, (0.0025949092, 1.3191798, 3.7633076, 0.07650198)\n",
      "decoder loss ratio: 0.309368, decoder SINDy loss  ratio: 0.195964\n",
      "THRESHOLDING: 4 active coefficients\n",
      "Epoch 1100\n",
      "   training loss 0.0007383311167359352, (0.00063730247, 0.20496091, 0.18046722, 0.054699894)\n",
      "   validation loss 0.0036291347350925207, (0.0021669166, 0.7483907, 2.848503, 0.054699894)\n",
      "decoder loss ratio: 0.258342, decoder SINDy loss  ratio: 0.148328\n",
      "Epoch 1200\n",
      "   training loss 0.00040622163214720786, (0.0003548872, 0.14351594, 0.08719177, 0.056276366)\n",
      "   validation loss 0.0029018453788012266, (0.0018441041, 0.5771247, 2.0566447, 0.056276366)\n",
      "decoder loss ratio: 0.219856, decoder SINDy loss  ratio: 0.107094\n",
      "Epoch 1300\n",
      "   training loss 0.00023278150183614343, (0.00020161452, 0.08207722, 0.052866302, 0.06299863)\n",
      "   validation loss 0.0024197567254304886, (0.0015898608, 0.38169146, 1.6203626, 0.06299863)\n",
      "decoder loss ratio: 0.189545, decoder SINDy loss  ratio: 0.084376\n",
      "Epoch 1400\n",
      "   training loss 0.00013492783182300627, (0.00011343622, 0.047954354, 0.03663804, 0.0774874)\n",
      "   validation loss 0.0020489171147346497, (0.0013994249, 0.35243443, 1.2621912, 0.0774874)\n",
      "decoder loss ratio: 0.166841, decoder SINDy loss  ratio: 0.065725\n",
      "Epoch 1500\n",
      "   training loss 7.56048975745216e-05, (5.9026406e-05, 0.032201596, 0.02819742, 0.086970545)\n",
      "   validation loss 0.0017551477067172527, (0.0012221626, 0.2925547, 1.0349753, 0.086970545)\n",
      "decoder loss ratio: 0.145708, decoder SINDy loss  ratio: 0.053894\n",
      "THRESHOLDING: 3 active coefficients\n",
      "Epoch 1600\n",
      "   training loss 4.879966581938788e-05, (3.4319233e-05, 0.021466477, 0.024900751, 0.09567345)\n",
      "   validation loss 0.001541354227811098, (0.001078328, 0.23833552, 0.90030545, 0.09567345)\n",
      "decoder loss ratio: 0.128559, decoder SINDy loss  ratio: 0.046881\n",
      "Epoch 1700\n",
      "   training loss 3.419526547077112e-05, (2.6269687e-05, 0.016354322, 0.012272256, 0.097173266)\n",
      "   validation loss 0.0013122957898303866, (0.0009208565, 0.24264553, 0.7566706, 0.097173266)\n",
      "decoder loss ratio: 0.109786, decoder SINDy loss  ratio: 0.039402\n",
      "Epoch 1800\n",
      "   training loss 3.394827217562124e-05, (2.097029e-05, 0.014438386, 0.022569342, 0.09713921)\n",
      "   validation loss 0.0009787218878045678, (0.0006688773, 0.3148729, 0.58625907, 0.09713921)\n",
      "decoder loss ratio: 0.079744, decoder SINDy loss  ratio: 0.030528\n",
      "Epoch 1900\n",
      "   training loss 2.3636845071450807e-05, (1.4817563e-05, 0.013314563, 0.014330375, 0.0988366)\n",
      "   validation loss 0.0008017887594178319, (0.00055884797, 0.17806184, 0.46609867, 0.0988366)\n",
      "decoder loss ratio: 0.066626, decoder SINDy loss  ratio: 0.024271\n",
      "Epoch 2000\n",
      "   training loss 2.0616167603293434e-05, (1.2086501e-05, 0.01279652, 0.013769229, 0.100522645)\n",
      "   validation loss 0.0007138829096220434, (0.0005033993, 0.1318603, 0.4057707, 0.100522645)\n",
      "decoder loss ratio: 0.060016, decoder SINDy loss  ratio: 0.021129\n",
      "THRESHOLDING: 3 active coefficients\n",
      "Epoch 2100\n",
      "   training loss 1.941978553077206e-05, (1.08749755e-05, 0.0127592785, 0.013818845, 0.099742204)\n",
      "   validation loss 0.0006399200647138059, (0.0004589616, 0.12270398, 0.3476516, 0.099742204)\n",
      "decoder loss ratio: 0.054718, decoder SINDy loss  ratio: 0.018103\n",
      "Epoch 2200\n",
      "   training loss 1.8066299162455834e-05, (9.774043e-06, 0.012834294, 0.013323285, 0.098889895)\n",
      "   validation loss 0.0005659870221279562, (0.00041362966, 0.1135343, 0.2913835, 0.098889895)\n",
      "decoder loss ratio: 0.049313, decoder SINDy loss  ratio: 0.015173\n",
      "Epoch 2300\n",
      "   training loss 1.7014614059007727e-05, (8.838994e-06, 0.012766398, 0.013100034, 0.09872835)\n",
      "   validation loss 0.0005003347177989781, (0.0003667471, 0.09745545, 0.25545514, 0.09872835)\n",
      "decoder loss ratio: 0.043724, decoder SINDy loss  ratio: 0.013302\n",
      "Epoch 2400\n",
      "   training loss 1.6240444892900996e-05, (8.0826485e-06, 0.012764368, 0.013069591, 0.098478235)\n",
      "   validation loss 0.0004407589149195701, (0.00032129936, 0.08288646, 0.22866088, 0.098478235)\n",
      "decoder loss ratio: 0.038306, decoder SINDy loss  ratio: 0.011907\n",
      "Epoch 2500\n",
      "   training loss 1.5589050235575996e-05, (7.4645113e-06, 0.012902217, 0.012998659, 0.0980098)\n",
      "   validation loss 0.0003852816007565707, (0.00027894918, 0.07191594, 0.203513, 0.0980098)\n",
      "decoder loss ratio: 0.033257, decoder SINDy loss  ratio: 0.010597\n",
      "THRESHOLDING: 3 active coefficients\n",
      "Epoch 2600\n",
      "   training loss 1.5061276826600078e-05, (6.9967355e-06, 0.013128652, 0.012866262, 0.09749774)\n",
      "   validation loss 0.00033348577562719584, (0.00024005705, 0.06377385, 0.1785301, 0.09749774)\n",
      "decoder loss ratio: 0.028620, decoder SINDy loss  ratio: 0.009296\n",
      "Epoch 2700\n",
      "   training loss 1.4586579709430225e-05, (6.5927957e-06, 0.013338697, 0.012712109, 0.09707949)\n",
      "   validation loss 0.0002853411715477705, (0.00020396257, 0.05943848, 0.15487179, 0.09707949)\n",
      "decoder loss ratio: 0.024317, decoder SINDy loss  ratio: 0.008065\n",
      "Epoch 2800\n",
      "   training loss 1.4135562196315732e-05, (6.208735e-06, 0.013350591, 0.01258325, 0.09676727)\n",
      "   validation loss 0.00024195353034883738, (0.00017071949, 0.05454779, 0.13507795, 0.09676727)\n",
      "decoder loss ratio: 0.020353, decoder SINDy loss  ratio: 0.007034\n",
      "Epoch 2900\n",
      "   training loss 1.3680160918738693e-05, (5.7764973e-06, 0.013363924, 0.01254801, 0.0961462)\n",
      "   validation loss 0.0002047217421932146, (0.00014093675, 0.049246337, 0.12072241, 0.0961462)\n",
      "decoder loss ratio: 0.016803, decoder SINDy loss  ratio: 0.006286\n",
      "Epoch 3000\n",
      "   training loss 1.3248833056422882e-05, (5.340606e-06, 0.013478144, 0.012564425, 0.09521062)\n",
      "   validation loss 0.00017511879559606314, (0.00011647293, 0.04581331, 0.11080619, 0.09521062)\n",
      "decoder loss ratio: 0.013886, decoder SINDy loss  ratio: 0.005770\n",
      "THRESHOLDING: 3 active coefficients\n",
      "Epoch 3100\n",
      "   training loss 1.2926493582199328e-05, (4.9874475e-06, 0.013654253, 0.012630671, 0.09409981)\n",
      "   validation loss 0.00015194194565992802, (9.757691e-05, 0.042896263, 0.10255845, 0.09409981)\n",
      "decoder loss ratio: 0.011633, decoder SINDy loss  ratio: 0.005340\n",
      "Epoch 3200\n",
      "   training loss 1.2727774446830153e-05, (4.7062704e-06, 0.013871371, 0.012799219, 0.092832625)\n",
      "   validation loss 0.00013337918790057302, (8.284443e-05, 0.040363636, 0.09517647, 0.092832625)\n",
      "decoder loss ratio: 0.009877, decoder SINDy loss  ratio: 0.004956\n",
      "Epoch 3300\n",
      "   training loss 1.2698318641923834e-05, (4.5144743e-06, 0.014104142, 0.013129031, 0.09141213)\n",
      "   validation loss 0.00011910493776667863, (7.152383e-05, 0.038008235, 0.08953314, 0.09141213)\n",
      "decoder loss ratio: 0.008527, decoder SINDy loss  ratio: 0.004662\n",
      "Epoch 3400\n",
      "   training loss 1.2638312909984961e-05, (4.3445266e-06, 0.014327034, 0.013357574, 0.0898647)\n",
      "   validation loss 0.00010840359755093232, (6.3334905e-05, 0.035801716, 0.084759906, 0.0898647)\n",
      "decoder loss ratio: 0.007551, decoder SINDy loss  ratio: 0.004414\n",
      "Epoch 3500\n",
      "   training loss 1.2499564945755992e-05, (4.1754474e-06, 0.014579548, 0.013426549, 0.088186525)\n",
      "   validation loss 0.0001000038901111111, (5.7415287e-05, 0.03468769, 0.0799447, 0.088186525)\n",
      "decoder loss ratio: 0.006845, decoder SINDy loss  ratio: 0.004163\n",
      "THRESHOLDING: 3 active coefficients\n",
      "Epoch 3600\n",
      "   training loss 1.2605349184013903e-05, (4.0817754e-06, 0.014858633, 0.013833724, 0.086378016)\n",
      "   validation loss 9.376959496876225e-05, (5.2903604e-05, 0.0349572, 0.0765087, 0.086378016)\n",
      "decoder loss ratio: 0.006307, decoder SINDy loss  ratio: 0.003984\n",
      "Epoch 3700\n",
      "   training loss 1.2256416084710509e-05, (3.8549947e-06, 0.01527957, 0.013602157, 0.08363641)\n",
      "   validation loss 8.779014024185017e-05, (4.96393e-05, 0.036756743, 0.07095327, 0.08363641)\n",
      "decoder loss ratio: 0.005918, decoder SINDy loss  ratio: 0.003695\n",
      "Epoch 3800\n",
      "   training loss 1.2183882972749416e-05, (3.7391278e-06, 0.015444636, 0.013721852, 0.08115976)\n",
      "   validation loss 8.249573147622868e-05, (4.64095e-05, 0.037265204, 0.066822745, 0.08115976)\n",
      "decoder loss ratio: 0.005533, decoder SINDy loss  ratio: 0.003480\n",
      "Epoch 3900\n",
      "   training loss 1.226288077305071e-05, (3.6927154e-06, 0.015659114, 0.01399806, 0.07881793)\n",
      "   validation loss 7.798577280482277e-05, (4.3368767e-05, 0.0381286, 0.06384478, 0.07881793)\n",
      "decoder loss ratio: 0.005170, decoder SINDy loss  ratio: 0.003325\n",
      "Epoch 4000\n",
      "   training loss 1.2349310964054894e-05, (3.6570411e-06, 0.015863558, 0.014273098, 0.076254345)\n",
      "   validation loss 7.41214826120995e-05, (4.07385e-05, 0.038411908, 0.061399683, 0.076254345)\n",
      "decoder loss ratio: 0.004857, decoder SINDy loss  ratio: 0.003197\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 4100\n",
      "   training loss 1.2571702427521814e-05, (3.6971855e-06, 0.016374134, 0.014695557, 0.0708032)\n",
      "   validation loss 7.082081720000133e-05, (3.858812e-05, 0.03724153, 0.059325173, 0.0708032)\n",
      "decoder loss ratio: 0.004601, decoder SINDy loss  ratio: 0.003089\n",
      "Epoch 4200\n",
      "   training loss 1.2570658327604178e-05, (3.6863344e-06, 0.016440133, 0.014713865, 0.07053847)\n",
      "   validation loss 6.76859708619304e-05, (3.645037e-05, 0.03552054, 0.05750837, 0.07053847)\n",
      "decoder loss ratio: 0.004346, decoder SINDy loss  ratio: 0.002995\n",
      "Epoch 4300\n",
      "   training loss 1.2545046047307551e-05, (3.6728993e-06, 0.01644405, 0.014692671, 0.07036086)\n",
      "   validation loss 6.47106789983809e-05, (3.4394237e-05, 0.0336447, 0.055861197, 0.07036086)\n",
      "decoder loss ratio: 0.004101, decoder SINDy loss  ratio: 0.002909\n",
      "Epoch 4400\n",
      "   training loss 1.2428485206328332e-05, (3.623873e-06, 0.016438229, 0.014561026, 0.07021868)\n",
      "   validation loss 6.164873775560409e-05, (3.2311804e-05, 0.03193593, 0.0540759, 0.07021868)\n",
      "decoder loss ratio: 0.003852, decoder SINDy loss  ratio: 0.002816\n",
      "Epoch 4500\n",
      "   training loss 1.2259001778147649e-05, (3.5679852e-06, 0.016470443, 0.014332961, 0.07010141)\n",
      "   validation loss 5.859358861926012e-05, (3.0274254e-05, 0.030510059, 0.052185632, 0.07010141)\n",
      "decoder loss ratio: 0.003609, decoder SINDy loss  ratio: 0.002717\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 4600\n",
      "   training loss 1.2202669495309237e-05, (3.5624e-06, 0.016544115, 0.014226212, 0.06999575)\n",
      "   validation loss 5.5936503486009315e-05, (2.833954e-05, 0.029493175, 0.050844688, 0.06999575)\n",
      "decoder loss ratio: 0.003379, decoder SINDy loss  ratio: 0.002648\n",
      "Epoch 4700\n",
      "   training loss 1.2332255209912546e-05, (3.6147464e-06, 0.0167193, 0.014364996, 0.069904484)\n",
      "   validation loss 5.388319186749868e-05, (2.6472639e-05, 0.029041534, 0.05051886, 0.069904484)\n",
      "decoder loss ratio: 0.003156, decoder SINDy loss  ratio: 0.002631\n",
      "Epoch 4800\n",
      "   training loss 1.2149613212386612e-05, (3.5400665e-06, 0.016760757, 0.01414655, 0.06982335)\n",
      "   validation loss 5.134688035468571e-05, (2.4694524e-05, 0.028182067, 0.04909004, 0.06982335)\n",
      "decoder loss ratio: 0.002944, decoder SINDy loss  ratio: 0.002556\n",
      "Epoch 4900\n",
      "   training loss 1.196921948576346e-05, (3.4558136e-06, 0.016678303, 0.0139644155, 0.06972826)\n",
      "   validation loss 4.898749466519803e-05, (2.306226e-05, 0.02716023, 0.04773988, 0.06972826)\n",
      "decoder loss ratio: 0.002750, decoder SINDy loss  ratio: 0.002486\n",
      "Epoch 5000\n",
      "   training loss 1.1901539437531028e-05, (3.4297132e-06, 0.016582826, 0.01389292, 0.06962242)\n",
      "   validation loss 4.6921184548409656e-05, (2.1582391e-05, 0.026205197, 0.046664618, 0.06962242)\n",
      "decoder loss ratio: 0.002573, decoder SINDy loss  ratio: 0.002430\n",
      "THRESHOLDING: 2 active coefficients\n",
      "REFINEMENT\n",
      "Epoch 0\n",
      "   training loss 1.2589433026732877e-05, (3.364832e-06, 0.016903454, 0.016758855, 0.069630414)\n",
      "   validation loss 4.871690907748416e-05, (2.1555705e-05, 0.026932593, 0.05162914, 0.069630414)\n",
      "decoder loss ratio: 0.002570, decoder SINDy loss  ratio: 0.002688\n",
      "Epoch 100\n",
      "   training loss 1.1049636668758467e-05, (3.3786653e-06, 0.015912315, 0.0137507105, 0.07034809)\n",
      "   validation loss 4.4393917050911114e-05, (2.0194982e-05, 0.025613004, 0.045836568, 0.07034809)\n",
      "decoder loss ratio: 0.002408, decoder SINDy loss  ratio: 0.002387\n",
      "Epoch 200\n",
      "   training loss 1.097133554139873e-05, (3.3509066e-06, 0.015851485, 0.013655708, 0.07026935)\n",
      "   validation loss 4.2665807995945215e-05, (1.8914887e-05, 0.024806669, 0.04502117, 0.07026935)\n",
      "decoder loss ratio: 0.002255, decoder SINDy loss  ratio: 0.002344\n",
      "Epoch 300\n",
      "   training loss 1.091392186935991e-05, (3.3516728e-06, 0.015731316, 0.013551366, 0.07016989)\n",
      "   validation loss 4.12852423323784e-05, (1.7727907e-05, 0.024026792, 0.044711992, 0.07016989)\n",
      "decoder loss ratio: 0.002114, decoder SINDy loss  ratio: 0.002328\n",
      "Epoch 400\n",
      "   training loss 1.0883695722441189e-05, (3.3346391e-06, 0.015562199, 0.013541893, 0.070103906)\n",
      "   validation loss 3.974431092501618e-05, (1.6591588e-05, 0.023257975, 0.04397965, 0.070103906)\n",
      "decoder loss ratio: 0.001978, decoder SINDy loss  ratio: 0.002290\n",
      "Epoch 500\n",
      "   training loss 1.08396870928118e-05, (3.3292135e-06, 0.0154300975, 0.013477936, 0.070048146)\n",
      "   validation loss 3.834024028037675e-05, (1.5596663e-05, 0.022502845, 0.043236867, 0.070048146)\n",
      "decoder loss ratio: 0.001859, decoder SINDy loss  ratio: 0.002251\n",
      "Epoch 600\n",
      "   training loss 1.0714775271480903e-05, (3.2862217e-06, 0.015342502, 0.013322855, 0.069994435)\n",
      "   validation loss 3.697301872307435e-05, (1.46615375e-05, 0.021691334, 0.04245383, 0.069994435)\n",
      "decoder loss ratio: 0.001748, decoder SINDy loss  ratio: 0.002211\n",
      "Epoch 700\n",
      "   training loss 1.0690426279325038e-05, (3.2789148e-06, 0.015181755, 0.013304846, 0.06995434)\n",
      "   validation loss 3.583506622817367e-05, (1.381918e-05, 0.020818174, 0.041949958, 0.06995434)\n",
      "decoder loss ratio: 0.001648, decoder SINDy loss  ratio: 0.002184\n",
      "Epoch 800\n",
      "   training loss 1.0600764653645456e-05, (3.2214261e-06, 0.015143238, 0.013244351, 0.069905356)\n",
      "   validation loss 3.4692740882746875e-05, (1.3004393e-05, 0.020216566, 0.04135504, 0.069905356)\n",
      "decoder loss ratio: 0.001550, decoder SINDy loss  ratio: 0.002153\n",
      "Epoch 900\n",
      "   training loss 1.0506299076951109e-05, (3.171567e-06, 0.015137938, 0.01315567, 0.0698523)\n",
      "   validation loss 3.356598608661443e-05, (1.2214648e-05, 0.019856282, 0.040717043, 0.0698523)\n",
      "decoder loss ratio: 0.001456, decoder SINDy loss  ratio: 0.002120\n",
      "Epoch 1000\n",
      "   training loss 1.060787690221332e-05, (3.230976e-06, 0.015239464, 0.013229856, 0.06966264)\n",
      "   validation loss 3.288753214292228e-05, (1.15628545e-05, 0.019999236, 0.04064943, 0.06966264)\n",
      "decoder loss ratio: 0.001379, decoder SINDy loss  ratio: 0.002117\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6256\\3717215364.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mresults_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'experiment_results_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y%m%d%H%M\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Leonardo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "num_experiments = 10\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_experiments):\n",
    "    print('EXPERIMENT %d' % i)\n",
    "\n",
    "    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "\n",
    "    params['save_name'] = 'pendulum_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    results_dict = train_network(training_data, validation_data, params)\n",
    "    df = df.append({**results_dict, **params}, ignore_index=True)\n",
    "\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
