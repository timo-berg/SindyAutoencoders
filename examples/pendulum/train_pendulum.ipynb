{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Leonardo\\AppData\\Local\\Temp\\ipykernel_21012\\1028156322.py:11: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_pendulum import get_pendulum_data\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = get_pendulum_data(100)\n",
    "validation_data = get_pendulum_data(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params['input_dim'] = training_data['x'].shape[-1]\n",
    "params['latent_dim'] = 1\n",
    "params['model_order'] = 2\n",
    "params['poly_order'] = 3\n",
    "params['include_sine'] = True\n",
    "params['library_dim'] = library_size(2*params['latent_dim'], params['poly_order'], params['include_sine'], True)\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = True\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 500\n",
    "params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_x'] = 5e-4\n",
    "params['loss_weight_sindy_z'] = 5e-5\n",
    "params['loss_weight_sindy_regularization'] = 1e-5\n",
    "\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [128,64,32]\n",
    "\n",
    "# training parameters\n",
    "params['epoch_size'] = training_data['x'].shape[0]\n",
    "params['batch_size'] = 1000\n",
    "params['learning_rate'] = 1e-4\n",
    "\n",
    "params['data_path'] = os.getcwd() + '/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 100\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 5001\n",
    "params['refinement_epochs'] = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n",
      "WARNING:tensorflow:From c:\\Users\\Leonardo\\OneDrive\\Tu Delft\\WI4450 Special Topics in Computational Science and Engineering\\SindyAutoencoders\\examples\\pendulum\\../../src\\training.py:12: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "TRAINING\n",
      "Epoch 0\n",
      "   training loss 0.02408435009419918, (0.008249346, 0.00066396705, 31.650017, 0.996192)\n",
      "   validation loss 0.01657882332801819, (0.008133821, 0.0004216345, 16.870039, 0.996192)\n",
      "decoder loss ratio: 0.969723, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 100\n",
      "   training loss 0.023528359830379486, (0.007698235, 5.9400274e-05, 31.650017, 0.51132095)\n",
      "   validation loss 0.015992337837815285, (0.007552202, 4.2785105e-05, 16.870039, 0.51132095)\n",
      "decoder loss ratio: 0.900382, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 200\n",
      "   training loss 0.023552976548671722, (0.0077274214, 0.002265967, 31.650017, 0.043185737)\n",
      "   validation loss 0.015969902276992798, (0.0075343796, 0.0014201283, 16.870039, 0.043185737)\n",
      "decoder loss ratio: 0.898257, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 300\n",
      "   training loss 0.02356213703751564, (0.007736083, 0.020096159, 31.650017, 0.0041611902)\n",
      "   validation loss 0.015966711565852165, (0.0075310552, 0.011899745, 16.870039, 0.0041611902)\n",
      "decoder loss ratio: 0.897861, decoder SINDy loss  ratio: 1.000000\n",
      "Epoch 400\n",
      "   training loss 0.022817431017756462, (0.00696839, 0.9599202, 31.600677, 0.07042902)\n",
      "   validation loss 0.015194181352853775, (0.006732483, 0.7990009, 16.842089, 0.07042902)\n",
      "decoder loss ratio: 0.802654, decoder SINDy loss  ratio: 0.998343\n",
      "Epoch 500\n",
      "   training loss 0.018630821257829666, (0.0063346676, 1.5012395, 24.440218, 0.098191656)\n",
      "   validation loss 0.012172667309641838, (0.0057615945, 1.0165517, 12.718526, 0.098191656)\n",
      "decoder loss ratio: 0.686904, decoder SINDy loss  ratio: 0.753912\n",
      "THRESHOLDING: 5 active coefficients\n",
      "Epoch 600\n",
      "   training loss 0.01274955552071333, (0.0052057593, 1.7116685, 14.915154, 0.06352391)\n",
      "   validation loss 0.0080879433080554, (0.004230206, 1.188185, 7.5953856, 0.06352391)\n",
      "decoder loss ratio: 0.504330, decoder SINDy loss  ratio: 0.450229\n",
      "Epoch 700\n",
      "   training loss 0.008412792347371578, (0.0041705184, 1.4149392, 8.341903, 0.057543974)\n",
      "   validation loss 0.005260415840893984, (0.0030732166, 0.92378396, 4.2808685, 0.057543974)\n",
      "decoder loss ratio: 0.366392, decoder SINDy loss  ratio: 0.253756\n",
      "Epoch 800\n",
      "   training loss 0.005390051286667585, (0.0030824302, 1.22893, 4.4911394, 0.060471836)\n",
      "   validation loss 0.0033065902534872293, (0.0020478864, 0.7266001, 2.4435387, 0.060471836)\n",
      "decoder loss ratio: 0.244151, decoder SINDy loss  ratio: 0.144845\n",
      "Epoch 900\n",
      "   training loss 0.003631100757047534, (0.0023893134, 1.0227282, 2.379916, 0.06928086)\n",
      "   validation loss 0.0022034673020243645, (0.0014743583, 0.62115633, 1.3947166, 0.06928086)\n",
      "decoder loss ratio: 0.175775, decoder SINDy loss  ratio: 0.082674\n",
      "Epoch 1000\n",
      "   training loss 0.0024360984098166227, (0.0016905178, 1.0134165, 1.3883532, 0.07332151)\n",
      "   validation loss 0.0014977380633354187, (0.001029141, 0.64950275, 0.87077737, 0.07332151)\n",
      "decoder loss ratio: 0.122695, decoder SINDy loss  ratio: 0.051617\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 1100\n",
      "   training loss 0.0016565031837671995, (0.0012033549, 0.77483535, 0.8276793, 0.05669084)\n",
      "   validation loss 0.001062549534253776, (0.00076554914, 0.52018195, 0.5408486, 0.05669084)\n",
      "decoder loss ratio: 0.091270, decoder SINDy loss  ratio: 0.032060\n",
      "Epoch 1200\n",
      "   training loss 0.0012577034067362547, (0.000925047, 0.57554066, 0.60673666, 0.051108424)\n",
      "   validation loss 0.0008279025205411017, (0.00060933334, 0.393783, 0.3967379, 0.051108424)\n",
      "decoder loss ratio: 0.072645, decoder SINDy loss  ratio: 0.023517\n",
      "Epoch 1300\n",
      "   training loss 0.0009287108550779521, (0.00070358155, 0.4276828, 0.40646887, 0.051072177)\n",
      "   validation loss 0.0006291332538239658, (0.00047640692, 0.30172554, 0.27425867, 0.051072177)\n",
      "decoder loss ratio: 0.056798, decoder SINDy loss  ratio: 0.016257\n",
      "Epoch 1400\n",
      "   training loss 0.0007351581589318812, (0.0005519967, 0.33704543, 0.33159152, 0.05134652)\n",
      "   validation loss 0.0005168357747606933, (0.00039079966, 0.24787644, 0.22625774, 0.05134652)\n",
      "decoder loss ratio: 0.046592, decoder SINDy loss  ratio: 0.013412\n",
      "Epoch 1500\n",
      "   training loss 0.0005844850675202906, (0.00043407292, 0.28782007, 0.2710144, 0.051389765)\n",
      "   validation loss 0.00042302985093556345, (0.00031836604, 0.23236716, 0.18506312, 0.051389765)\n",
      "decoder loss ratio: 0.037956, decoder SINDy loss  ratio: 0.010970\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 1600\n",
      "   training loss 0.00044732613605447114, (0.0003293605, 0.2542527, 0.20948294, 0.051150937)\n",
      "   validation loss 0.00032806582748889923, (0.0002451171, 0.22027133, 0.14284736, 0.051150937)\n",
      "decoder loss ratio: 0.029223, decoder SINDy loss  ratio: 0.008468\n",
      "Epoch 1700\n",
      "   training loss 0.0003411568468436599, (0.00024772782, 0.23105042, 0.16273879, 0.050709367)\n",
      "   validation loss 0.00024850713089108467, (0.00018195303, 0.20339131, 0.11175488, 0.050709367)\n",
      "decoder loss ratio: 0.021693, decoder SINDy loss  ratio: 0.006624\n",
      "Epoch 1800\n",
      "   training loss 0.0002739325282163918, (0.00019650016, 0.2030565, 0.13355576, 0.050166484)\n",
      "   validation loss 0.00019313726807013154, (0.00013730042, 0.1814473, 0.092525624, 0.050166484)\n",
      "decoder loss ratio: 0.016369, decoder SINDy loss  ratio: 0.005485\n",
      "Epoch 1900\n",
      "   training loss 0.00023402964870911092, (0.00016981114, 0.18743896, 0.10870331, 0.049489632)\n",
      "   validation loss 0.00015476980479434133, (0.00010744462, 0.16718233, 0.07694235, 0.049489632)\n",
      "decoder loss ratio: 0.012810, decoder SINDy loss  ratio: 0.004561\n",
      "Epoch 2000\n",
      "   training loss 0.0002084941224893555, (0.00015554887, 0.16898051, 0.08801571, 0.048836913)\n",
      "   validation loss 0.00012768655142281204, (8.750923e-05, 0.15334146, 0.06404377, 0.048836913)\n",
      "decoder loss ratio: 0.010433, decoder SINDy loss  ratio: 0.003796\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 2100\n",
      "   training loss 0.00018817404634319246, (0.00014289482, 0.15132187, 0.07445892, 0.04836816)\n",
      "   validation loss 0.0001103501781472005, (7.482355e-05, 0.14221802, 0.055864096, 0.04836816)\n",
      "decoder loss ratio: 0.008921, decoder SINDy loss  ratio: 0.003311\n",
      "Epoch 2200\n",
      "   training loss 0.0001665683084866032, (0.00012632355, 0.14544412, 0.06498523, 0.047994297)\n",
      "   validation loss 9.618681360734627e-05, (6.362739e-05, 0.13881059, 0.050277893, 0.047994297)\n",
      "decoder loss ratio: 0.007586, decoder SINDy loss  ratio: 0.002980\n",
      "Epoch 2300\n",
      "   training loss 0.0001445506641175598, (0.000107897955, 0.14118303, 0.058233216, 0.047696035)\n",
      "   validation loss 8.446891297353432e-05, (5.4107873e-05, 0.13698152, 0.046070002, 0.047696035)\n",
      "decoder loss ratio: 0.006451, decoder SINDy loss  ratio: 0.002731\n",
      "Epoch 2400\n",
      "   training loss 0.00012172965216450393, (8.7663626e-05, 0.14043249, 0.05314, 0.047440264)\n",
      "   validation loss 7.40994219086133e-05, (4.5350873e-05, 0.13722844, 0.04282546, 0.047440264)\n",
      "decoder loss ratio: 0.005407, decoder SINDy loss  ratio: 0.002539\n",
      "Epoch 2500\n",
      "   training loss 0.00010186737927142531, (7.0061855e-05, 0.1414794, 0.04851858, 0.047226477)\n",
      "   validation loss 6.570185360033065e-05, (3.817426e-05, 0.13851424, 0.040259227, 0.047226477)\n",
      "decoder loss ratio: 0.004551, decoder SINDy loss  ratio: 0.002386\n",
      "THRESHOLDING: 1 active coefficients\n",
      "Epoch 2600\n",
      "   training loss 8.816264744382352e-05, (5.7424913e-05, 0.14933267, 0.04570955, 0.041632783)\n",
      "   validation loss 5.977826731395908e-05, (3.2957894e-05, 0.14268208, 0.038539883, 0.041632783)\n",
      "decoder loss ratio: 0.003929, decoder SINDy loss  ratio: 0.002285\n",
      "Epoch 2700\n",
      "   training loss 7.805578934494406e-05, (4.8892667e-05, 0.14948343, 0.0426129, 0.03825026)\n",
      "   validation loss 5.514461008715443e-05, (2.9173503e-05, 0.14354968, 0.036822237, 0.03825026)\n",
      "decoder loss ratio: 0.003478, decoder SINDy loss  ratio: 0.002183\n",
      "Epoch 2800\n",
      "   training loss 0.00019835565763060004, (5.015013e-05, 0.1503757, 0.2806079, 0.038276974)\n",
      "   validation loss 0.00012701191008090973, (3.7204554e-05, 0.14449488, 0.16439967, 0.038276974)\n",
      "decoder loss ratio: 0.004436, decoder SINDy loss  ratio: 0.009745\n",
      "Epoch 2900\n",
      "   training loss 6.659662903985009e-05, (3.927013e-05, 0.15105456, 0.038781654, 0.038293812)\n",
      "   validation loss 4.9183850933331996e-05, (2.4253834e-05, 0.14602719, 0.034491442, 0.038293812)\n",
      "decoder loss ratio: 0.002892, decoder SINDy loss  ratio: 0.002045\n",
      "Epoch 3000\n",
      "   training loss 9.749337186804041e-05, (3.9749186e-05, 0.15547599, 0.09917448, 0.03831481)\n",
      "   validation loss 6.754199421266094e-05, (2.6613718e-05, 0.14931464, 0.0661588, 0.03831481)\n",
      "decoder loss ratio: 0.003173, decoder SINDy loss  ratio: 0.003922\n",
      "THRESHOLDING: 1 active coefficients\n",
      "Epoch 3100\n",
      "   training loss 6.483501783804968e-05, (3.508414e-05, 0.15461035, 0.04327418, 0.03832689)\n",
      "   validation loss 4.778998118126765e-05, (2.1756381e-05, 0.14960717, 0.036339942, 0.03832689)\n",
      "decoder loss ratio: 0.002594, decoder SINDy loss  ratio: 0.002154\n",
      "Epoch 3200\n",
      "   training loss 5.942358257016167e-05, (3.3389693e-05, 0.15476665, 0.03582469, 0.038320955)\n",
      "   validation loss 4.4293716200627387e-05, (2.0236761e-05, 0.1502193, 0.032325562, 0.038320955)\n",
      "decoder loss ratio: 0.002413, decoder SINDy loss  ratio: 0.001916\n",
      "Epoch 3300\n",
      "   training loss 5.787355257780291e-05, (3.2328e-05, 0.15643728, 0.03468078, 0.038330056)\n",
      "   validation loss 4.30865547969006e-05, (1.9258143e-05, 0.15187632, 0.03170259, 0.038330056)\n",
      "decoder loss ratio: 0.002296, decoder SINDy loss  ratio: 0.001879\n",
      "Epoch 3400\n",
      "   training loss 5.6843131460482255e-05, (3.1586835e-05, 0.15847322, 0.033898827, 0.03832197)\n",
      "   validation loss 4.220193295623176e-05, (1.8495286e-05, 0.15383145, 0.031263705, 0.03832197)\n",
      "decoder loss ratio: 0.002205, decoder SINDy loss  ratio: 0.001853\n",
      "Epoch 3500\n",
      "   training loss 5.634211265714839e-05, (3.1133815e-05, 0.16058528, 0.033591658, 0.03832017)\n",
      "   validation loss 4.158707452006638e-05, (1.7954142e-05, 0.15568367, 0.030931097, 0.03832017)\n",
      "decoder loss ratio: 0.002141, decoder SINDy loss  ratio: 0.001833\n",
      "THRESHOLDING: 1 active coefficients\n",
      "Epoch 3600\n",
      "   training loss 5.5854630772955716e-05, (3.0597315e-05, 0.16066372, 0.03368177, 0.038324635)\n",
      "   validation loss 4.1029103158507496e-05, (1.7457589e-05, 0.15597497, 0.030779034, 0.038324635)\n",
      "decoder loss ratio: 0.002081, decoder SINDy loss  ratio: 0.001824\n",
      "Epoch 3700\n",
      "   training loss 5.500942643266171e-05, (3.0165054e-05, 0.1617948, 0.0327428, 0.03832308)\n",
      "   validation loss 4.036872269352898e-05, (1.6963924e-05, 0.15695472, 0.030347664, 0.03832308)\n",
      "decoder loss ratio: 0.002022, decoder SINDy loss  ratio: 0.001799\n",
      "Epoch 3800\n",
      "   training loss 5.479835090227425e-05, (2.9787665e-05, 0.16249967, 0.033004988, 0.038320985)\n",
      "   validation loss 4.0020117012318224e-05, (1.6632803e-05, 0.15761018, 0.030247184, 0.038320985)\n",
      "decoder loss ratio: 0.001983, decoder SINDy loss  ratio: 0.001793\n",
      "Epoch 3900\n",
      "   training loss 8.302131755044684e-05, (3.1628075e-05, 0.16555434, 0.08546456, 0.038324792)\n",
      "   validation loss 5.6411881814710796e-05, (1.9323757e-05, 0.15968123, 0.057441633, 0.038324792)\n",
      "decoder loss ratio: 0.002304, decoder SINDy loss  ratio: 0.003405\n",
      "Epoch 4000\n",
      "   training loss 5.359703573049046e-05, (2.9031562e-05, 0.1639562, 0.03196878, 0.038327027)\n",
      "   validation loss 3.909688166459091e-05, (1.5929249e-05, 0.15872364, 0.029696357, 0.038327027)\n",
      "decoder loss ratio: 0.001899, decoder SINDy loss  ratio: 0.001760\n",
      "THRESHOLDING: 1 active coefficients\n",
      "Epoch 4100\n",
      "   training loss 5.3338844736572355e-05, (2.8708795e-05, 0.16402182, 0.032091435, 0.038323816)\n",
      "   validation loss 3.8834612496430054e-05, (1.5707094e-05, 0.15877217, 0.02961134, 0.038323816)\n",
      "decoder loss ratio: 0.001873, decoder SINDy loss  ratio: 0.001755\n",
      "Epoch 4200\n",
      "   training loss 6.119267345638946e-05, (2.930898e-05, 0.16565515, 0.04643526, 0.0383302)\n",
      "   validation loss 4.3104937503812835e-05, (1.651555e-05, 0.15985624, 0.036426548, 0.0383302)\n",
      "decoder loss ratio: 0.001969, decoder SINDy loss  ratio: 0.002159\n",
      "Epoch 4300\n",
      "   training loss 0.00012447586050257087, (3.2067004e-05, 0.16788657, 0.16726238, 0.03833406)\n",
      "   validation loss 8.086062007350847e-05, (2.1617387e-05, 0.16129914, 0.10158986, 0.03833406)\n",
      "decoder loss ratio: 0.002577, decoder SINDy loss  ratio: 0.006022\n",
      "Epoch 4400\n",
      "   training loss 5.285279257805087e-05, (2.8013967e-05, 0.16533838, 0.03237721, 0.03832994)\n",
      "   validation loss 3.8413683796534315e-05, (1.52281655e-05, 0.15963802, 0.029640628, 0.03832994)\n",
      "decoder loss ratio: 0.001816, decoder SINDy loss  ratio: 0.001757\n",
      "Epoch 4500\n",
      "   training loss 6.989423127379268e-05, (2.9167768e-05, 0.16606058, 0.06408021, 0.03833241)\n",
      "   validation loss 4.80978014820721e-05, (1.6933836e-05, 0.16003866, 0.04555742, 0.03833241)\n",
      "decoder loss ratio: 0.002019, decoder SINDy loss  ratio: 0.002700\n",
      "THRESHOLDING: 1 active coefficients\n",
      "Epoch 4600\n",
      "   training loss 9.387659520143643e-05, (3.0069674e-05, 0.16659442, 0.11018776, 0.038331844)\n",
      "   validation loss 6.236158515093848e-05, (1.8778204e-05, 0.16036838, 0.070363276, 0.038331844)\n",
      "decoder loss ratio: 0.002239, decoder SINDy loss  ratio: 0.004171\n",
      "Epoch 4700\n",
      "   training loss 5.071609120932408e-05, (2.704934e-05, 0.16323078, 0.030243728, 0.038334604)\n",
      "   validation loss 3.696784551721066e-05, (1.4547601e-05, 0.15805995, 0.0282678, 0.038334604)\n",
      "decoder loss ratio: 0.001734, decoder SINDy loss  ratio: 0.001676\n",
      "Epoch 4800\n",
      "   training loss 5.5684457038296387e-05, (2.741643e-05, 0.16340032, 0.039429326, 0.038334455)\n",
      "   validation loss 3.96302821172867e-05, (1.5091083e-05, 0.15807104, 0.032504603, 0.038334455)\n",
      "decoder loss ratio: 0.001799, decoder SINDy loss  ratio: 0.001927\n",
      "Epoch 4900\n",
      "   training loss 5.0572329200804234e-05, (2.6649084e-05, 0.16207205, 0.030872501, 0.038339365)\n",
      "   validation loss 3.674581239465624e-05, (1.4346548e-05, 0.15709901, 0.02832185, 0.038339365)\n",
      "decoder loss ratio: 0.001710, decoder SINDy loss  ratio: 0.001679\n",
      "Epoch 5000\n",
      "   training loss 4.9387625040253624e-05, (2.6333511e-05, 0.1612511, 0.029216455, 0.03833297)\n",
      "   validation loss 3.6103243473917246e-05, (1.41056025e-05, 0.15644023, 0.027584597, 0.03833297)\n",
      "decoder loss ratio: 0.001682, decoder SINDy loss  ratio: 0.001635\n",
      "THRESHOLDING: 1 active coefficients\n",
      "REFINEMENT\n",
      "Epoch 0\n",
      "   training loss 5.701117333956063e-05, (2.7378148e-05, 0.16771564, 0.042494487, 0.038368527)\n",
      "   validation loss 4.0267044823849574e-05, (1.5067252e-05, 0.15984851, 0.03441473, 0.038368527)\n",
      "decoder loss ratio: 0.001796, decoder SINDy loss  ratio: 0.002040\n",
      "Epoch 100\n",
      "   training loss 9.54067800194025e-05, (2.8848079e-05, 0.16430303, 0.116687104, 0.038467884)\n",
      "   validation loss 6.29729765933007e-05, (1.8236851e-05, 0.158066, 0.07366565, 0.038467884)\n",
      "decoder loss ratio: 0.002174, decoder SINDy loss  ratio: 0.004367\n",
      "Epoch 200\n",
      "   training loss 5.27504671481438e-05, (2.6370206e-05, 0.16189776, 0.036570743, 0.03847588)\n",
      "   validation loss 3.760600520763546e-05, (1.438727e-05, 0.15636396, 0.030801075, 0.03847588)\n",
      "decoder loss ratio: 0.001715, decoder SINDy loss  ratio: 0.001826\n",
      "Epoch 300\n",
      "   training loss 4.7914149035932496e-05, (2.5626354e-05, 0.16049533, 0.028526051, 0.038478334)\n",
      "   validation loss 3.4973469155374914e-05, (1.368131e-05, 0.15535079, 0.027049238, 0.038478334)\n",
      "decoder loss ratio: 0.001631, decoder SINDy loss  ratio: 0.001603\n",
      "Epoch 400\n",
      "   training loss 9.023954044096172e-05, (2.7950335e-05, 0.16195346, 0.10838305, 0.038486242)\n",
      "   validation loss 5.980282730888575e-05, (1.7476337e-05, 0.15611932, 0.06904104, 0.038486242)\n",
      "decoder loss ratio: 0.002084, decoder SINDy loss  ratio: 0.004093\n",
      "Epoch 500\n",
      "   training loss 4.767052087117918e-05, (2.5531488e-05, 0.1591416, 0.028363902, 0.038490582)\n",
      "   validation loss 3.5037490306422114e-05, (1.3759966e-05, 0.15402777, 0.02715227, 0.038490582)\n",
      "decoder loss ratio: 0.001640, decoder SINDy loss  ratio: 0.001609\n",
      "Epoch 600\n",
      "   training loss 4.652162897400558e-05, (2.4898472e-05, 0.15784405, 0.02746191, 0.03850079)\n",
      "   validation loss 3.409836062928662e-05, (1.32455625e-05, 0.15311159, 0.02639444, 0.03850079)\n",
      "decoder loss ratio: 0.001579, decoder SINDy loss  ratio: 0.001565\n",
      "Epoch 700\n",
      "   training loss 4.6682514948770404e-05, (2.470802e-05, 0.1570074, 0.028248247, 0.03851023)\n",
      "   validation loss 3.40949154633563e-05, (1.3179454e-05, 0.15239576, 0.026591348, 0.03851023)\n",
      "decoder loss ratio: 0.001571, decoder SINDy loss  ratio: 0.001576\n",
      "Epoch 800\n",
      "   training loss 4.555527266347781e-05, (2.4388573e-05, 0.15621619, 0.026711775, 0.03851889)\n",
      "   validation loss 3.351812483742833e-05, (1.2937697e-05, 0.15172604, 0.025988253, 0.03851889)\n",
      "decoder loss ratio: 0.001542, decoder SINDy loss  ratio: 0.001540\n",
      "Epoch 900\n",
      "   training loss 4.7244644520105794e-05, (2.4917048e-05, 0.15594411, 0.029060775, 0.03852891)\n",
      "   validation loss 3.475896664895117e-05, (1.3642655e-05, 0.15140672, 0.027091952, 0.03852891)\n",
      "decoder loss ratio: 0.001626, decoder SINDy loss  ratio: 0.001606\n",
      "Epoch 1000\n",
      "   training loss 4.4606807932723314e-05, (2.384001e-05, 0.1543063, 0.02610296, 0.038539197)\n",
      "   validation loss 3.2936975912889466e-05, (1.2629993e-05, 0.15012261, 0.025601706, 0.038539197)\n",
      "decoder loss ratio: 0.001506, decoder SINDy loss  ratio: 0.001518\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21012\\3717215364.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mresults_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'experiment_results_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y%m%d%H%M\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Leonardo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "num_experiments = 10\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_experiments):\n",
    "    print('EXPERIMENT %d' % i)\n",
    "\n",
    "    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "\n",
    "    params['save_name'] = 'pendulum_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    results_dict = train_network(training_data, validation_data, params)\n",
    "    df = df.append({**results_dict, **params}, ignore_index=True)\n",
    "\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
